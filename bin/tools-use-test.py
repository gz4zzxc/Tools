#!/usr/bin/env python3
"""
OpenAI/Anthropic æ ¼å¼æ¨¡å‹åŠŸèƒ½æµ‹è¯•è„šæœ¬
æ”¯æŒäº¤äº’å¼è¾“å…¥å‚æ•°ï¼Œæµ‹è¯•æ¨¡å‹æ˜¯å¦æ”¯æŒï¼š
- åŸºæœ¬èŠå¤©åŠŸèƒ½
- å·¥å…·è°ƒç”¨åŠŸèƒ½
- æµå¼å“åº”
- å›¾ç‰‡è¾“å…¥æ”¯æŒ
"""

import base64
import json
import mimetypes
import sys
import urllib.error
from urllib.request import Request, urlopen
from typing import Dict, Any, Optional
from openai import OpenAI
from openai.types.chat import ChatCompletionToolParam
import time
import math
import re


def get_user_input(prompt: str, default: str = "") -> str:
    """è·å–ç”¨æˆ·è¾“å…¥ï¼Œæ”¯æŒé»˜è®¤å€¼"""
    if default:
        user_input = input(f"{prompt} (é»˜è®¤: {default}): ").strip()
        return user_input if user_input else default
    else:
        return input(f"{prompt}: ").strip()


def get_model_parameters() -> Dict[str, str]:
    """äº¤äº’å¼è·å–æ¨¡å‹å‚æ•°"""
    print("=== OpenAI/Anthropic æ ¼å¼æ¨¡å‹å·¥å…·ä½¿ç”¨æµ‹è¯• ===\n")

    print("è¯·é€‰æ‹© API æ ¼å¼:")
    print("  1) openai")
    print("  2) anthropic")
    api_choice = get_user_input("è¯·è¾“å…¥é€‰é¡¹", "1").strip().lower()

    if api_choice in {"1", "openai"}:
        api_format = "openai"
    elif api_choice in {"2", "anthropic"}:
        api_format = "anthropic"
    else:
        print(f"âš ï¸  ä¸æ”¯æŒçš„é€‰é¡¹: {api_choice}ï¼Œå°†ä½¿ç”¨ 1) openai")
        api_format = "openai"

    default_base_url = "http://localhost:8000/v1" if api_format == "openai" else "http://localhost:8000"
    base_url = get_user_input("è¯·è¾“å…¥ base_url", default_base_url)
    api_key = get_user_input("è¯·è¾“å…¥ api_key", "sk-xxx")
    model_name = get_user_input("è¯·è¾“å…¥æ¨¡å‹åç§°", "deepseek-ai/DeepSeek-V3.1")

    params = {
        "api_format": api_format,
        "base_url": base_url,
        "api_key": api_key,
        "model_name": model_name
    }
    if api_format == "anthropic":
        params["anthropic_version"] = "2023-06-01"
    return params


def get_test_image_url() -> str:
    """è·å–æµ‹è¯•å›¾ç‰‡çš„ URL"""
    # ä½¿ç”¨ä¸€ä¸ªå…¬å¼€çš„æµ‹è¯•å›¾ç‰‡ URLï¼ˆè‹¥ä¸‹è½½å¤±è´¥ä¼šè‡ªåŠ¨å›é€€åˆ°å†…ç½®å›¾ç‰‡ï¼‰
    return "https://picsum.photos/512/320"


def get_builtin_test_image_base64() -> tuple[str, str]:
    """è¿”å›å†…ç½®æµ‹è¯•å›¾ç‰‡ï¼ˆ1x1 PNGï¼‰çš„ base64 æ•°æ®"""
    return (
        "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAwMCAO7+S84AAAAASUVORK5CYII=",
        "image/png",
    )


def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬ token æ•°"""
    if not text:
        return 0
    cjk = re.findall(r"[\u4e00-\u9fff]", text)
    cjk_count = len(cjk)
    non_cjk_count = len(text) - cjk_count
    approx = cjk_count + math.ceil(non_cjk_count / 4)
    return max(approx, 1) if text.strip() else 0


def get_tool_definitions() -> list[Dict[str, Any]]:
    """è¿”å›ç»Ÿä¸€å·¥å…·å®šä¹‰"""
    return [
        {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°"
                    },
                    "date": {
                        "type": "string",
                        "description": "æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DD"
                    }
                },
                "required": ["city"]
            }
        },
        {
            "name": "calculate",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ 2+3*4"
                    }
                },
                "required": ["expression"]
            }
        }
    ]


def create_test_tools_openai() -> list[ChatCompletionToolParam]:
    """åˆ›å»º OpenAI æ ¼å¼å·¥å…·å®šä¹‰"""
    tools: list[ChatCompletionToolParam] = []
    for tool in get_tool_definitions():
        tools.append(
            {
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool["parameters"]
                }
            }
        )
    return tools


def create_test_tools_anthropic() -> list[Dict[str, Any]]:
    """åˆ›å»º Anthropic æ ¼å¼å·¥å…·å®šä¹‰"""
    tools = []
    for tool in get_tool_definitions():
        tools.append(
            {
                "name": tool["name"],
                "description": tool["description"],
                "input_schema": tool["parameters"]
            }
        )
    return tools


def normalize_anthropic_messages_url(base_url: str) -> str:
    """å°† base_url è§„èŒƒåŒ–ä¸º Anthropic messages æ¥å£ URL"""
    cleaned = base_url.rstrip("/")
    if cleaned.endswith("/v1/messages"):
        return cleaned
    if cleaned.endswith("/v1"):
        return f"{cleaned}/messages"
    return f"{cleaned}/v1/messages"


def create_anthropic_headers(api_key: str, anthropic_version: str, stream: bool = False) -> Dict[str, str]:
    """åˆ›å»º Anthropic è¯·æ±‚å¤´"""
    headers = {
        "content-type": "application/json",
        "x-api-key": api_key,
        "anthropic-version": anthropic_version,
    }
    if stream:
        headers["accept"] = "text/event-stream"
    return headers


def anthropic_messages_create(params: Dict[str, str], payload: Dict[str, Any]) -> Dict[str, Any]:
    """è°ƒç”¨ Anthropic messages æ¥å£ï¼ˆéæµå¼ï¼‰"""
    url = normalize_anthropic_messages_url(params["base_url"])
    req = Request(
        url=url,
        data=json.dumps(payload).encode("utf-8"),
        headers=create_anthropic_headers(params["api_key"], params["anthropic_version"]),
        method="POST",
    )
    try:
        with urlopen(req, timeout=180) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except urllib.error.HTTPError as e:
        error_body = e.read().decode("utf-8", errors="replace")
        raise RuntimeError(f"HTTP {e.code}: {error_body}") from e
    except urllib.error.URLError as e:
        raise RuntimeError(f"ç½‘ç»œé”™è¯¯: {e}") from e


def anthropic_stream_events(params: Dict[str, str], payload: Dict[str, Any]):
    """è°ƒç”¨ Anthropic messages æ¥å£ï¼ˆæµå¼ï¼‰ï¼ŒæŒ‰ SSE äº‹ä»¶äº§å‡º JSON"""
    stream_payload = dict(payload)
    stream_payload["stream"] = True
    url = normalize_anthropic_messages_url(params["base_url"])
    req = Request(
        url=url,
        data=json.dumps(stream_payload).encode("utf-8"),
        headers=create_anthropic_headers(params["api_key"], params["anthropic_version"], stream=True),
        method="POST",
    )
    try:
        with urlopen(req, timeout=300) as resp:
            data_lines: list[str] = []
            for raw_line in resp:
                line = raw_line.decode("utf-8", errors="ignore").strip()
                if not line:
                    if not data_lines:
                        continue
                    raw_data = "\n".join(data_lines).strip()
                    data_lines = []
                    if raw_data == "[DONE]":
                        break
                    try:
                        event = json.loads(raw_data)
                    except json.JSONDecodeError:
                        continue
                    yield event
                    continue
                if line.startswith("data:"):
                    data_lines.append(line[len("data:"):].strip())
    except urllib.error.HTTPError as e:
        error_body = e.read().decode("utf-8", errors="replace")
        raise RuntimeError(f"HTTP {e.code}: {error_body}") from e
    except urllib.error.URLError as e:
        raise RuntimeError(f"ç½‘ç»œé”™è¯¯: {e}") from e


def extract_anthropic_text(content_blocks: list[Dict[str, Any]]) -> str:
    """ä» Anthropic content æ•°ç»„æå–æ–‡æœ¬"""
    texts = []
    for block in content_blocks:
        if block.get("type") == "text" and block.get("text"):
            texts.append(block["text"])
    return "".join(texts)


def get_anthropic_output_tokens(response: Dict[str, Any]) -> Optional[int]:
    """è·å– Anthropic è¿”å›çš„ output_tokens"""
    usage = response.get("usage") or {}
    output_tokens = usage.get("output_tokens")
    if output_tokens is None:
        return None
    try:
        return int(output_tokens)
    except Exception:
        return None


def normalize_anthropic_tool_calls(content_blocks: list[Dict[str, Any]]) -> list[Dict[str, Any]]:
    """è§„èŒƒåŒ–å·¥å…·è°ƒç”¨ï¼Œå…¼å®¹éƒ¨åˆ†ç½‘å…³æŠŠ name/input æ‹†æˆå¤šä¸ª block çš„æƒ…å†µ"""
    normalized: list[Dict[str, Any]] = []
    for block in content_blocks:
        if block.get("type") != "tool_use":
            continue

        name = (block.get("name") or "").strip()
        input_payload = block.get("input") or {}
        if not isinstance(input_payload, dict):
            input_payload = {"raw_arguments": str(input_payload)}

        if name:
            normalized.append({"name": name, "input": input_payload})
            continue

        if not normalized:
            normalized.append({"name": "", "input": input_payload})
            continue

        prev_input = normalized[-1].get("input")
        if isinstance(prev_input, dict) and prev_input.get("raw_arguments", "") == "" and len(prev_input) == 1:
            normalized[-1]["input"] = input_payload
        elif isinstance(prev_input, dict):
            prev_input.update(input_payload)
        else:
            normalized[-1]["input"] = input_payload

    return normalized


def anthropic_messages_create_with_tool_choice_fallback(
    params: Dict[str, str], payload: Dict[str, Any]
) -> Dict[str, Any]:
    """å¸¦ tool_choice å…¼å®¹é™çº§çš„ Anthropic éæµå¼è¯·æ±‚"""
    try:
        return anthropic_messages_create(params, payload)
    except RuntimeError as e:
        err = str(e).lower()
        if "tool_choice" not in err or "tool_choice" not in payload:
            raise
        fallback_payload = dict(payload)
        fallback_payload.pop("tool_choice", None)
        print("âš ï¸  æœåŠ¡ç«¯ä¸æ”¯æŒ tool_choiceï¼Œå·²è‡ªåŠ¨é™çº§é‡è¯•")
        return anthropic_messages_create(params, fallback_payload)


def anthropic_stream_events_with_tool_choice_fallback(params: Dict[str, str], payload: Dict[str, Any]):
    """å¸¦ tool_choice å…¼å®¹é™çº§çš„ Anthropic æµå¼è¯·æ±‚"""
    try:
        yield from anthropic_stream_events(params, payload)
    except RuntimeError as e:
        err = str(e).lower()
        if "tool_choice" not in err or "tool_choice" not in payload:
            raise
        fallback_payload = dict(payload)
        fallback_payload.pop("tool_choice", None)
        print("âš ï¸  æœåŠ¡ç«¯ä¸æ”¯æŒ tool_choiceï¼Œå·²è‡ªåŠ¨é™çº§é‡è¯•")
        yield from anthropic_stream_events(params, fallback_payload)


def load_image_as_base64(image_url: str) -> tuple[str, str]:
    """ä¸‹è½½å›¾ç‰‡å¹¶è½¬ä¸º base64ï¼Œè¿”å› (base64_data, media_type)"""
    req = Request(image_url, headers={"User-Agent": "tools-use-test/1.0"})
    try:
        with urlopen(req, timeout=120) as resp:
            image_bytes = resp.read()
            media_type = resp.headers.get_content_type()
    except urllib.error.HTTPError as e:
        error_body = e.read().decode("utf-8", errors="replace")
        raise RuntimeError(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼ŒHTTP {e.code}: {error_body}") from e
    except urllib.error.URLError as e:
        raise RuntimeError(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}") from e

    if not media_type or media_type == "application/octet-stream":
        guessed_media_type, _ = mimetypes.guess_type(image_url)
        media_type = guessed_media_type or "image/jpeg"

    return base64.b64encode(image_bytes).decode("utf-8"), media_type


def test_basic_chat(client: OpenAI, model_name: str) -> bool:
    """æµ‹è¯•åŸºæœ¬çš„èŠå¤©åŠŸèƒ½"""
    print("\n=== æµ‹è¯•åŸºæœ¬èŠå¤©åŠŸèƒ½ ===")
    try:
        start_ts = time.perf_counter()
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
            max_tokens=100
        )
        end_ts = time.perf_counter()
        ttft_ms = max((end_ts - start_ts) * 1000.0, 0.0)
        print("âœ… åŸºæœ¬èŠå¤©åŠŸèƒ½æ­£å¸¸")
        message = response.choices[0].message
        print(f"å›å¤: {message.content}")
        print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")

        # ç»Ÿè®¡è¾“å‡º tokens ä¸é€Ÿç‡
        completion_tokens = None
        try:
            if getattr(response, "usage", None) and getattr(response.usage, "completion_tokens", None) is not None:
                completion_tokens = int(response.usage.completion_tokens)
        except Exception:
            completion_tokens = None

        if completion_tokens is None:
            completion_tokens = estimate_tokens(message.content or "")

        total_s = max(end_ts - start_ts, 1e-9)
        tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
        print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
        return True
    except Exception as e:
        print(f"âŒ åŸºæœ¬èŠå¤©åŠŸèƒ½å¤±è´¥: {e}")
        return False


def test_tools_usage(client: OpenAI, model_name: str, tools: list[ChatCompletionToolParam]) -> bool:
    """æµ‹è¯•å·¥å…·ä½¿ç”¨åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å·¥å…·ä½¿ç”¨åŠŸèƒ½ ===")
    try:
        start_ts = time.perf_counter()
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": "è¯·å¸®æˆ‘æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”"}],
            tools=tools,
            tool_choice="auto",
            max_tokens=200
        )
        end_ts = time.perf_counter()
        ttft_ms = max((end_ts - start_ts) * 1000.0, 0.0)
        
        message = response.choices[0].message
        if message.tool_calls:
            print("âœ… æ¨¡å‹æ”¯æŒå·¥å…·è°ƒç”¨ï¼")
            for tool_call in message.tool_calls:
                print(f"å·¥å…·åç§°: {tool_call.function.name}")
                print(f"å‚æ•°: {tool_call.function.arguments}")
            print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
            # ç»Ÿè®¡è¾“å‡º tokens ä¸é€Ÿç‡ï¼ˆä»¥ usage ä¸ºå‡†ï¼Œè‹¥æ— åˆ™ä¼°ç®—ä¸º 0ï¼‰
            completion_tokens = None
            try:
                if getattr(response, "usage", None) and getattr(response.usage, "completion_tokens", None) is not None:
                    completion_tokens = int(response.usage.completion_tokens)
            except Exception:
                completion_tokens = None

            if completion_tokens is None:
                completion_tokens = 0

            total_s = max(end_ts - start_ts, 1e-9)
            tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
            print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
            return True
        else:
            print("âš ï¸  æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œä½†è¯·æ±‚æˆåŠŸ")
            print(f"å›å¤: {message.content}")
            print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
            # ç»Ÿè®¡è¾“å‡º tokens ä¸é€Ÿç‡
            completion_tokens = None
            try:
                if getattr(response, "usage", None) and getattr(response.usage, "completion_tokens", None) is not None:
                    completion_tokens = int(response.usage.completion_tokens)
            except Exception:
                completion_tokens = None

            if completion_tokens is None:
                completion_tokens = estimate_tokens(message.content or "")

            total_s = max(end_ts - start_ts, 1e-9)
            tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
            print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
            return False
            
    except Exception as e:
        print(f"âŒ å·¥å…·ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_streaming_with_tools(client: OpenAI, model_name: str, tools: list[ChatCompletionToolParam]) -> bool:
    """æµ‹è¯•æµå¼å“åº”ä¸­çš„å·¥å…·ä½¿ç”¨"""
    print("\n=== æµ‹è¯•æµå¼å·¥å…·ä½¿ç”¨ ===")
    try:
        start_ts = time.perf_counter()
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": "è¯·è®¡ç®— 15 * 23 çš„ç»“æœ"}],
                tools=tools,
                tool_choice="auto",
                stream=True,
                max_tokens=200,
                stream_options={"include_usage": True}
            )
        except TypeError:
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": "è¯·è®¡ç®— 15 * 23 çš„ç»“æœ"}],
                tools=tools,
                tool_choice="auto",
                stream=True,
                max_tokens=200
            )
        
        print("æµå¼å“åº”:")
        tool_calls_found = False
        content_parts = []
        first_content_ts = None
        first_any_ts = None
        final_usage_completion_tokens = None
        
        for chunk in response:
            if chunk.choices[0].delta.tool_calls:
                tool_calls_found = True
                print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨...")
                if first_any_ts is None:
                    first_any_ts = time.perf_counter()
            
            if chunk.choices[0].delta.content:
                content_parts.append(chunk.choices[0].delta.content)
                print(chunk.choices[0].delta.content, end="", flush=True)
                now_ts = time.perf_counter()
                if first_content_ts is None:
                    first_content_ts = now_ts
                if first_any_ts is None:
                    first_any_ts = now_ts

            # å°è¯•åœ¨æµæœ«å°¾è·å– usageï¼ˆéœ€æœåŠ¡ç«¯æ”¯æŒ include_usageï¼‰
            try:
                usage = getattr(chunk, "usage", None)
                if usage and getattr(usage, "completion_tokens", None) is not None:
                    final_usage_completion_tokens = int(usage.completion_tokens)
            except Exception:
                pass
        
        end_ts = time.perf_counter()

        if tool_calls_found:
            print("\nâœ… æµå¼å“åº”ä¸­æ”¯æŒå·¥å…·è°ƒç”¨")
        else:
            print("\nâš ï¸  æµå¼å“åº”ä¸­æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
        
        # ç»Ÿè®¡ TTFT ä¸è¾“å‡ºé€Ÿç‡
        ttft_ref = first_content_ts or first_any_ts
        if ttft_ref is not None:
            ttft_ms = max((ttft_ref - start_ts) * 1000.0, 0.0)
            print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
        else:
            print("â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: æœªæ£€æµ‹åˆ°é¦–ä¸ªå¢é‡")

        if final_usage_completion_tokens is None:
            final_text = "".join(content_parts)
            # ä¼°ç®— tokensï¼ˆæ—  usage æ—¶ï¼‰
            final_usage_completion_tokens = estimate_tokens(final_text)

        # è¾“å‡ºé€Ÿç‡åŸºäºé¦–å­—åˆ°ç»“æŸçš„æ—¶é•¿ï¼Œè‹¥æ— åˆ™ç”¨æ€»æ—¶é•¿
        start_for_speed = (first_content_ts or first_any_ts or start_ts)
        duration_s = max(end_ts - start_for_speed, 1e-9)
        tok_per_s = final_usage_completion_tokens / duration_s if duration_s > 0 else float("inf")
        print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {final_usage_completion_tokens} tokens / {duration_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")

        return tool_calls_found
        
    except Exception as e:
        print(f"âŒ æµå¼å·¥å…·ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_image_support(client: OpenAI, model_name: str) -> bool:
    """æµ‹è¯•æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾ç‰‡è¾“å…¥"""
    print("\n=== æµ‹è¯•å›¾ç‰‡æ”¯æŒåŠŸèƒ½ ===")
    try:
        # è·å–æµ‹è¯•å›¾ç‰‡ URL
        test_image_url = get_test_image_url()
        
        # æ„å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "è¯·æè¿°ä¸€ä¸‹è¿™å¼ å›¾ç‰‡çš„å†…å®¹"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": test_image_url
                        }
                    }
                ]
            }
        ]
        
        start_ts = time.perf_counter()
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            max_tokens=200
        )
        end_ts = time.perf_counter()
        
        message = response.choices[0].message
        if message.content:
            print("âœ… æ¨¡å‹æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼")
            print(f"å›¾ç‰‡æè¿°: {message.content}")
            
            # ç»Ÿè®¡è¾“å‡º tokens ä¸é€Ÿç‡
            completion_tokens = None
            try:
                if getattr(response, "usage", None) and getattr(response.usage, "completion_tokens", None) is not None:
                    completion_tokens = int(response.usage.completion_tokens)
            except Exception:
                completion_tokens = None

            if completion_tokens is None:
                completion_tokens = estimate_tokens(message.content or "")

            total_s = max(end_ts - start_ts, 1e-9)
            tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
            print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
            return True
        else:
            print("âš ï¸  æ¨¡å‹æ¥å—äº†å›¾ç‰‡è¾“å…¥ä½†æ²¡æœ‰è¿”å›å†…å®¹")
            return False
            
    except Exception as e:
        error_msg = str(e).lower()
        if "vision" in error_msg or "image" in error_msg or "multimodal" in error_msg:
            print("âŒ æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
        else:
            print(f"âŒ å›¾ç‰‡æ”¯æŒæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_basic_chat_anthropic(params: Dict[str, str]) -> bool:
    """æµ‹è¯• Anthropic æ ¼å¼çš„åŸºæœ¬èŠå¤©åŠŸèƒ½"""
    print("\n=== æµ‹è¯•åŸºæœ¬èŠå¤©åŠŸèƒ½ï¼ˆAnthropicï¼‰===")
    try:
        start_ts = time.perf_counter()
        response = anthropic_messages_create(
            params,
            {
                "model": params["model_name"],
                "messages": [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
                "max_tokens": 100,
            },
        )
        end_ts = time.perf_counter()
        ttft_ms = max((end_ts - start_ts) * 1000.0, 0.0)

        content_blocks = response.get("content") or []
        message_text = extract_anthropic_text(content_blocks)
        print("âœ… åŸºæœ¬èŠå¤©åŠŸèƒ½æ­£å¸¸")
        print(f"å›å¤: {message_text or '[ç©ºå›å¤]'}")
        print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")

        completion_tokens = get_anthropic_output_tokens(response)
        if completion_tokens is None:
            completion_tokens = estimate_tokens(message_text)

        total_s = max(end_ts - start_ts, 1e-9)
        tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
        print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
        return True
    except Exception as e:
        print(f"âŒ åŸºæœ¬èŠå¤©åŠŸèƒ½å¤±è´¥: {e}")
        return False


def test_tools_usage_anthropic(params: Dict[str, str], tools: list[Dict[str, Any]]) -> bool:
    """æµ‹è¯• Anthropic æ ¼å¼çš„å·¥å…·ä½¿ç”¨åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å·¥å…·ä½¿ç”¨åŠŸèƒ½ï¼ˆAnthropicï¼‰===")
    try:
        start_ts = time.perf_counter()
        response = anthropic_messages_create_with_tool_choice_fallback(
            params,
            {
                "model": params["model_name"],
                "messages": [{"role": "user", "content": "è¯·å¸®æˆ‘æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”"}],
                "tools": tools,
                "tool_choice": {"type": "auto"},
                "max_tokens": 200,
            },
        )
        end_ts = time.perf_counter()
        ttft_ms = max((end_ts - start_ts) * 1000.0, 0.0)

        content_blocks = response.get("content") or []
        tool_calls = normalize_anthropic_tool_calls(content_blocks)
        message_text = extract_anthropic_text(content_blocks)

        if tool_calls:
            print("âœ… æ¨¡å‹æ”¯æŒå·¥å…·è°ƒç”¨ï¼")
            for tool_call in tool_calls:
                print(f"å·¥å…·åç§°: {tool_call.get('name', '')}")
                print(f"å‚æ•°: {json.dumps(tool_call.get('input', {}), ensure_ascii=False)}")
            print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
            completion_tokens = get_anthropic_output_tokens(response)
            if completion_tokens is None:
                completion_tokens = 0

            total_s = max(end_ts - start_ts, 1e-9)
            tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
            print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
            return True

        print("âš ï¸  æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œä½†è¯·æ±‚æˆåŠŸ")
        print(f"å›å¤: {message_text or '[ç©ºå›å¤]'}")
        print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
        completion_tokens = get_anthropic_output_tokens(response)
        if completion_tokens is None:
            completion_tokens = estimate_tokens(message_text)

        total_s = max(end_ts - start_ts, 1e-9)
        tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
        print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
        return False

    except Exception as e:
        print(f"âŒ å·¥å…·ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_streaming_with_tools_anthropic(params: Dict[str, str], tools: list[Dict[str, Any]]) -> bool:
    """æµ‹è¯• Anthropic æ ¼å¼æµå¼å“åº”ä¸­çš„å·¥å…·ä½¿ç”¨"""
    print("\n=== æµ‹è¯•æµå¼å·¥å…·ä½¿ç”¨ï¼ˆAnthropicï¼‰===")
    try:
        start_ts = time.perf_counter()
        payload = {
            "model": params["model_name"],
            "messages": [{"role": "user", "content": "è¯·è®¡ç®— 15 * 23 çš„ç»“æœ"}],
            "tools": tools,
            "tool_choice": {"type": "auto"},
            "max_tokens": 200,
        }

        print("æµå¼å“åº”:")
        tool_calls_found = False
        content_parts: list[str] = []
        first_content_ts = None
        first_any_ts = None
        final_usage_completion_tokens = None

        for event in anthropic_stream_events_with_tool_choice_fallback(params, payload):
            event_type = event.get("type")

            # è®°å½• usageï¼ˆAnthropic é€šå¸¸åœ¨ message_delta äº‹ä»¶å†…è¿”å›ï¼‰
            usage = event.get("usage") or {}
            output_tokens = usage.get("output_tokens")
            if output_tokens is not None:
                try:
                    final_usage_completion_tokens = int(output_tokens)
                except Exception:
                    pass

            if event_type == "content_block_start":
                block = event.get("content_block") or {}
                block_type = block.get("type")
                if block_type == "tool_use":
                    tool_calls_found = True
                    print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨...")
                    if first_any_ts is None:
                        first_any_ts = time.perf_counter()
                elif block_type == "text":
                    text = block.get("text", "")
                    if text:
                        content_parts.append(text)
                        print(text, end="", flush=True)
                        now_ts = time.perf_counter()
                        if first_content_ts is None:
                            first_content_ts = now_ts
                        if first_any_ts is None:
                            first_any_ts = now_ts
                continue

            if event_type == "content_block_delta":
                delta = event.get("delta") or {}
                delta_type = delta.get("type")
                if delta_type == "text_delta":
                    text = delta.get("text", "")
                    if text:
                        content_parts.append(text)
                        print(text, end="", flush=True)
                        now_ts = time.perf_counter()
                        if first_content_ts is None:
                            first_content_ts = now_ts
                        if first_any_ts is None:
                            first_any_ts = now_ts
                elif delta_type == "input_json_delta":
                    tool_calls_found = True
                    if first_any_ts is None:
                        first_any_ts = time.perf_counter()

        end_ts = time.perf_counter()

        if tool_calls_found:
            print("\nâœ… æµå¼å“åº”ä¸­æ”¯æŒå·¥å…·è°ƒç”¨")
        else:
            print("\nâš ï¸  æµå¼å“åº”ä¸­æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")

        ttft_ref = first_content_ts or first_any_ts
        if ttft_ref is not None:
            ttft_ms = max((ttft_ref - start_ts) * 1000.0, 0.0)
            print(f"â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: {ttft_ms:.0f} ms")
        else:
            print("â³ é¦–å­—å»¶è¿Ÿï¼ˆTTFTï¼‰: æœªæ£€æµ‹åˆ°é¦–ä¸ªå¢é‡")

        if final_usage_completion_tokens is None:
            final_usage_completion_tokens = estimate_tokens("".join(content_parts))

        start_for_speed = first_content_ts or first_any_ts or start_ts
        duration_s = max(end_ts - start_for_speed, 1e-9)
        tok_per_s = final_usage_completion_tokens / duration_s if duration_s > 0 else float("inf")
        print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {final_usage_completion_tokens} tokens / {duration_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")

        return tool_calls_found
    except Exception as e:
        print(f"âŒ æµå¼å·¥å…·ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_image_support_anthropic(params: Dict[str, str]) -> bool:
    """æµ‹è¯• Anthropic æ ¼å¼æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾ç‰‡è¾“å…¥"""
    print("\n=== æµ‹è¯•å›¾ç‰‡æ”¯æŒåŠŸèƒ½ï¼ˆAnthropicï¼‰===")
    try:
        test_image_url = get_test_image_url()
        try:
            image_b64, media_type = load_image_as_base64(test_image_url)
        except Exception as download_error:
            print(f"âš ï¸  æµ‹è¯•å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…ç½®å›¾ç‰‡ç»§ç»­æµ‹è¯•: {download_error}")
            image_b64, media_type = get_builtin_test_image_base64()

        payload = {
            "model": params["model_name"],
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¯·æè¿°ä¸€ä¸‹è¿™å¼ å›¾ç‰‡çš„å†…å®¹"},
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": media_type,
                                "data": image_b64,
                            },
                        },
                    ],
                }
            ],
            "max_tokens": 200,
        }

        start_ts = time.perf_counter()
        response = anthropic_messages_create(params, payload)
        end_ts = time.perf_counter()

        content_blocks = response.get("content") or []
        message_text = extract_anthropic_text(content_blocks)
        if message_text:
            print("âœ… æ¨¡å‹æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼")
            print(f"å›¾ç‰‡æè¿°: {message_text}")
            completion_tokens = get_anthropic_output_tokens(response)
            if completion_tokens is None:
                completion_tokens = estimate_tokens(message_text)

            total_s = max(end_ts - start_ts, 1e-9)
            tok_per_s = completion_tokens / total_s if total_s > 0 else float("inf")
            print(f"â±ï¸ è¾“å‡ºé€Ÿç‡: {completion_tokens} tokens / {total_s:.2f}s â‰ˆ {tok_per_s:.2f} tok/s")
            return True

        print("âš ï¸  æ¨¡å‹æ¥å—äº†å›¾ç‰‡è¾“å…¥ä½†æ²¡æœ‰è¿”å›å†…å®¹")
        return False

    except Exception as e:
        if str(e).startswith("ä¸‹è½½å›¾ç‰‡å¤±è´¥"):
            print("âŒ å›¾ç‰‡æµ‹è¯•å¤±è´¥ï¼ˆæµ‹è¯•å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œä¸ä»£è¡¨æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ï¼‰")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
            return False
        error_msg = str(e).lower()
        if "http 401" in error_msg and "openai_api_key" in error_msg:
            print("âŒ å›¾ç‰‡æµ‹è¯•å¤±è´¥ï¼ˆé‰´æƒå¤±è´¥ï¼Œä¸ä»£è¡¨æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ï¼‰")
            print("é”™è¯¯ä¿¡æ¯: ç½‘å…³è¿”å›ã€ŒInvalid API key / OPENAI_API_KEYã€ï¼Œè¯·æ£€æŸ¥ä¼ å…¥çš„ ModelScope Token æ˜¯å¦æ­£ç¡®ä¸”æœ‰è¯¥æ¨¡å‹æƒé™ã€‚")
            print(f"åŸå§‹é”™è¯¯: {e}")
            return False
        if "vision" in error_msg or "image" in error_msg or "multimodal" in error_msg:
            print("âŒ æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
        else:
            print(f"âŒ å›¾ç‰‡æ”¯æŒæµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        params = get_model_parameters()
        
        api_format = params["api_format"]
        print(f"\næ­£åœ¨è¿æ¥åˆ°: {params['base_url']} (æ ¼å¼: {api_format})")

        if api_format == "anthropic":
            tools = create_test_tools_anthropic()
            basic_success = test_basic_chat_anthropic(params)
            tools_success = test_tools_usage_anthropic(params, tools)
            streaming_success = test_streaming_with_tools_anthropic(params, tools)
            image_success = test_image_support_anthropic(params)
        else:
            client = OpenAI(
                base_url=params['base_url'],
                api_key=params['api_key']
            )
            tools = create_test_tools_openai()
            basic_success = test_basic_chat(client, params['model_name'])
            tools_success = test_tools_usage(client, params['model_name'], tools)
            streaming_success = test_streaming_with_tools(client, params['model_name'], tools)
            image_success = test_image_support(client, params['model_name'])
        
        # æ€»ç»“æµ‹è¯•ç»“æœ
        print("\n" + "="*50)
        print("æµ‹è¯•ç»“æœæ€»ç»“:")
        print(f"åŸºæœ¬èŠå¤©åŠŸèƒ½: {'âœ… é€šè¿‡' if basic_success else 'âŒ å¤±è´¥'}")
        print(f"å·¥å…·ä½¿ç”¨åŠŸèƒ½: {'âœ… é€šè¿‡' if tools_success else 'âŒ å¤±è´¥'}")
        print(f"æµå¼å·¥å…·ä½¿ç”¨: {'âœ… é€šè¿‡' if streaming_success else 'âŒ å¤±è´¥'}")
        print(f"å›¾ç‰‡æ”¯æŒåŠŸèƒ½: {'âœ… é€šè¿‡' if image_success else 'âŒ å¤±è´¥'}")
        
        # åŠŸèƒ½æ”¯æŒæ€»ç»“
        print("\nåŠŸèƒ½æ”¯æŒæ€»ç»“:")
        if tools_success:
            print("ğŸ‰ è¯¥æ¨¡å‹æ”¯æŒå·¥å…·ä½¿ç”¨ï¼")
        else:
            print("âš ï¸  è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå·¥å…·ä½¿ç”¨")
            
        if image_success:
            print("ğŸ–¼ï¸  è¯¥æ¨¡å‹æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼")
        else:
            print("âš ï¸  è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥")
            
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
